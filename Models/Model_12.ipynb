{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Tixonmavrin/Zindi-Zimnat-Insurance-Recommendation-Challenge/blob/master/Baseline1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QfCbUjWSgMTJ"
   },
   "source": [
    "##Zimnat Insurance Recommendation Challenge\n",
    "Can you predict which insurance products existing clients will want next?\n",
    "###Baseline with catboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "82PpxfmqglcE"
   },
   "source": [
    "### Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3arOHSJwCtNq"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "import sklearn\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import uniform as sp_randFloat\n",
    "from scipy.stats import randint as sp_randInt\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "import pprint\n",
    "import joblib\n",
    "from xgboost.sklearn import XGBClassifier \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Classifiers\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# Model selection\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "# Skopt functions\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.callbacks import DeadlineStopper, VerboseCallback, DeltaXStopper\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s3ZCXtzKDiDe"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('Train.csv')\n",
    "test = pd.read_csv('Test.csv')\n",
    "submission = pd.read_csv('SampleSubmission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o_ELVeoVgv3v"
   },
   "source": [
    "### New format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oxjj_QAfEyZw"
   },
   "outputs": [],
   "source": [
    "X_train = []\n",
    "X_train_columns = train.columns\n",
    "c = 0\n",
    "for v in train.values:\n",
    "    info = v[:8]\n",
    "    binary = v[8:]\n",
    "    index = [k for k, i in enumerate(binary) if i == 1]\n",
    "    for i in index:\n",
    "        c+=1\n",
    "        for k in range(len(binary)):\n",
    "            if k == i:\n",
    "                binary_transformed = list(copy.copy(binary))\n",
    "                binary_transformed[i] = 0\n",
    "                X_train.append(list(info) + binary_transformed + [X_train_columns[8+k]] + [c])\n",
    "\n",
    "X_train = pd.DataFrame(X_train)\n",
    "X_train.columns = ['ID', 'join_date', 'sex', 'marital_status', 'birth_year', 'branch_code',\n",
    "       'occupation_code', 'occupation_category_code', 'P5DA', 'RIBP', '8NN1',\n",
    "       '7POT', '66FJ', 'GYSR', 'SOP4', 'RVSZ', 'PYUQ', 'LJR9', 'N2MW', 'AHXO',\n",
    "       'BSTQ', 'FM3X', 'K6QO', 'QBOL', 'JWFN', 'JZ9D', 'J9JW', 'GHYX', 'ECY3', 'product_pred', 'ID2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "URdSMgJeOnLE"
   },
   "outputs": [],
   "source": [
    "X_test = []\n",
    "true_values = []\n",
    "c = 0\n",
    "for v in test.values:\n",
    "    c += 1\n",
    "    info = v[:8]\n",
    "    binary = v[8:]\n",
    "    index = [k for k, i in enumerate(binary) if i == 1]\n",
    "    X_test.append(list(info) + list(binary) + [c])\n",
    "    for k in test.columns[8:][index]:\n",
    "        true_values.append(v[0] + ' X ' + k)\n",
    "\n",
    "X_test = pd.DataFrame(X_test)\n",
    "X_test.columns = ['ID', 'join_date', 'sex', 'marital_status', 'birth_year', 'branch_code',\n",
    "       'occupation_code', 'occupation_category_code', 'P5DA', 'RIBP', '8NN1',\n",
    "       '7POT', '66FJ', 'GYSR', 'SOP4', 'RVSZ', 'PYUQ', 'LJR9', 'N2MW', 'AHXO',\n",
    "       'BSTQ', 'FM3X', 'K6QO', 'QBOL', 'JWFN', 'JZ9D', 'J9JW', 'GHYX', 'ECY3', 'ID2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s1KcI9I6g1de"
   },
   "source": [
    "### Transform data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ttUKNdnAczTd"
   },
   "outputs": [],
   "source": [
    "features_train = []\n",
    "features_test = []\n",
    "columns = []\n",
    "\n",
    "append_features = ['P5DA', 'RIBP', '8NN1', '7POT', '66FJ', 'GYSR', 'SOP4', 'RVSZ', 'PYUQ', 'LJR9', \n",
    "'N2MW', 'AHXO','BSTQ', 'FM3X', 'K6QO', 'QBOL', 'JWFN', 'JZ9D', 'J9JW', 'GHYX', \n",
    "'ECY3', 'ID', 'ID2', 'join_date', 'sex', 'marital_status', 'branch_code', 'occupation_code', 'occupation_category_code',\n",
    "'birth_year']\n",
    "for v in append_features:\n",
    "    features_train.append(X_train[v].values.reshape(-1, 1))\n",
    "    features_test.append(X_test[v].values.reshape(-1, 1))\n",
    "    columns.append(np.array([v]))\n",
    "\n",
    "y_train = X_train[['product_pred']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kWCK5LrfkPp-"
   },
   "outputs": [],
   "source": [
    "features_train = np.concatenate(features_train, axis=1)\n",
    "features_test = np.concatenate(features_test, axis=1)\n",
    "columns = np.concatenate(np.array(columns))\n",
    "\n",
    "X_train = pd.DataFrame(features_train)\n",
    "X_train.columns = columns\n",
    "X_test = pd.DataFrame(features_test)\n",
    "X_test.columns = columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YVUKKo3llI0y"
   },
   "source": [
    "### New features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NhfA7yullH76"
   },
   "outputs": [],
   "source": [
    "X_train['date1'] = X_train['join_date'].apply(lambda x: int(x.split('/')[0]) if (x == x) else np.nan)\n",
    "X_train['date2'] = X_train['join_date'].apply(lambda x: int(x.split('/')[1]) if (x == x) else np.nan)\n",
    "X_train['date3'] = X_train['join_date'].apply(lambda x: int(x.split('/')[2]) if (x == x) else np.nan)\n",
    "X_train.drop('join_date', axis=1, inplace=True)\n",
    "\n",
    "X_test['date1'] = X_test['join_date'].apply(lambda x: int(x.split('/')[0]) if (x == x) else np.nan)\n",
    "X_test['date2'] = X_test['join_date'].apply(lambda x: int(x.split('/')[1]) if (x == x) else np.nan)\n",
    "X_test['date3'] = X_test['join_date'].apply(lambda x: int(x.split('/')[2]) if (x == x) else np.nan)\n",
    "X_test.drop('join_date', axis=1, inplace=True)\n",
    "\n",
    "X_train['date_diff'] = X_train['date3'] - X_train['birth_year']\n",
    "X_test['date_diff'] = X_test['date3'] - X_test['birth_year']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GDTy7qyulLoP"
   },
   "source": [
    "### Change types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YFf8xSoc3kN4"
   },
   "outputs": [],
   "source": [
    "X_train = X_train.fillna(0)\n",
    "X_test = X_test.fillna(0)\n",
    "y_train = y_train.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mTCyVmQjS9nv"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "data = X_train.append(X_test)\n",
    "for v in ['sex', 'marital_status', 'branch_code', 'occupation_code', 'occupation_category_code',]:\n",
    "    data.loc[:,v] = le.fit_transform(data.loc[:,v])\n",
    "X_train = data[:X_train.shape[0]]\n",
    "X_test = data[-X_test.shape[0]:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OtwJsy7ZnIuO"
   },
   "outputs": [],
   "source": [
    "le.fit(y_train.iloc[:,0])\n",
    "y_train = pd.DataFrame(le.transform(y_train.iloc[:,0]))\n",
    "y_train.columns = ['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['join_date'] = pd.to_datetime(train['join_date'])\n",
    "train['year'] = train['join_date'].dt.year\n",
    "train['month'] = train['join_date'].dt.month\n",
    "train['day'] = train['join_date'].dt.day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['join_date'] = pd.to_datetime(test['join_date'])\n",
    "test['year'] = test['join_date'].dt.year\n",
    "test['month'] = test['join_date'].dt.month\n",
    "test['day'] = test['join_date'].dt.day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['year'] = train['year']\n",
    "X_train['month'] = train['month']\n",
    "X_train['day'] = train['day']\n",
    "pd.set_option('display.max_columns', None)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['year'] = test['year']\n",
    "X_test['month'] = test['month']\n",
    "X_test['day'] = test['day']\n",
    "pd.set_option('display.max_columns', None)\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qn9zHq0iqhA3"
   },
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "kANA1SPmgfS6",
    "outputId": "78dc5019-8af1-444e-9c3e-2874c532577f"
   },
   "outputs": [],
   "source": [
    "# model = CatBoostClassifier()\n",
    "# parameters = {'depth'         : sp_randInt(4, 10),\n",
    "#               'learning_rate' : sp_randFloat(),\n",
    "#               'iterations'    : sp_randInt(10, 100)\n",
    "#              }\n",
    "\n",
    "# randm = RandomizedSearchCV(estimator=model, param_distributions = parameters,\n",
    "#                            cv = 2, n_iter = 10, n_jobs=-1)\n",
    "# randm.fit(X_train.drop(columns=['ID', 'ID2']), y_train, cat_features=['sex','marital_status','branch_code','occupation_code','occupation_category_code'])\n",
    "\n",
    "# # Results from Random Search\n",
    "# print(\"\\n========================================================\")\n",
    "# print(\" Results from Random Search \" )\n",
    "# print(\"========================================================\")\n",
    "# print(\"\\n The best estimator across ALL searched params:\\n\",randm.best_estimator_)\n",
    "# print(\"\\n The best score across ALL searched params:\\n\",randm.best_score_)\n",
    "# print(\"\\n The best parameters across ALL searched params:\\n\",randm.best_params_)\n",
    "# print(\"\\n ========================================================\")\n",
    "# # model = CatBoostClassifier()\n",
    "# # model.fit(X_train.drop(columns=['ID', 'ID2']), y_train, cat_features=['sex','marital_status','branch_code','occupation_code','occupation_category_code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = CatBoostClassifier(depth= 7, iterations= 79, learning_rate= 0.24800286296598373)\n",
    "# model.fit(X_train.drop(columns=['ID', 'ID2']), y_train, cat_features=['sex','marital_status','branch_code','occupation_code','occupation_category_code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def report_perf(optimizer, X, y, title, callbacks=None):\n",
    "#     \"\"\"\n",
    "#     A wrapper for measuring time and performances of different optmizers\n",
    "    \n",
    "#     optimizer = a sklearn or a skopt optimizer\n",
    "#     X = the training set \n",
    "#     y = our target\n",
    "#     title = a string label for the experiment\n",
    "#     \"\"\"\n",
    "#     start = time()\n",
    "#     if callbacks:\n",
    "#         optimizer.fit(X, y, callback=callbacks, cat_features=['sex','marital_status','branch_code','occupation_code','occupation_category_code'])\n",
    "#     else:\n",
    "#         optimizer.fit(X, y, cat_features=['sex','marital_status','branch_code','occupation_code','occupation_category_code'])\n",
    "#     d=pd.DataFrame(optimizer.cv_results_)\n",
    "#     best_score = optimizer.best_score_\n",
    "#     best_score_std = d.iloc[optimizer.best_index_].std_test_score\n",
    "#     best_params = optimizer.best_params_\n",
    "#     print((title + \" took %.2f seconds,  candidates checked: %d, best CV score: %.3f \"\n",
    "#            +u\"\\u00B1\"+\" %.3f\") % (time() - start, \n",
    "#                                   len(optimizer.cv_results_['params']),\n",
    "#                                   best_score,\n",
    "#                                   best_score_std))    \n",
    "#     print('Best parameters:')\n",
    "#     pprint.pprint(best_params)\n",
    "#     print()\n",
    "#     return best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# roc_auc = make_scorer(roc_auc_score, greater_is_better=True, needs_threshold=True)\n",
    "# skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf = CatBoostClassifier(cat_features=['sex','marital_status','branch_code','occupation_code','occupation_category_code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search_spaces = {'iterations': Integer(10, 1000),\n",
    "#                  'depth': Integer(1, 8),\n",
    "#                  'learning_rate': Real(0.01, 1.0, 'log-uniform'),\n",
    "#                  'random_strength': Real(1e-9, 10, 'log-uniform'),\n",
    "#                  'bagging_temperature': Real(0.0, 1.0),\n",
    "#                  'border_count': Integer(1, 255),\n",
    "#                  'l2_leaf_reg': Integer(2, 30),\n",
    "#                  'scale_pos_weight':Real(0.01, 1.0, 'uniform')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Setting up BayesSearchCV\n",
    "# opt = BayesSearchCV(clf,\n",
    "#                     search_spaces,\n",
    "#                     scoring=roc_auc,\n",
    "#                     cv=skf,\n",
    "#                     n_iter=100,\n",
    "#                     n_jobs=1,  # use just 1 job with CatBoost in order to avoid segmentation fault\n",
    "#                     return_train_score=False,\n",
    "#                     refit=True,\n",
    "#                     optimizer_kwargs={'base_estimator': 'GP'},\n",
    "#                     random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Random Forest\n",
    "\n",
    "# rf = RandomForestClassifier(\n",
    "#     n_estimators=421, \n",
    "#     max_depth=15,\n",
    "#     max_features=3,\n",
    "#     min_samples_split=8, \n",
    "#     class_weight=\"balanced\",\n",
    "#     bootstrap=True,\n",
    "#     criterion='entropy',\n",
    "#     random_state=100\n",
    "#     )\n",
    "\n",
    "# rf.fit(X_train.drop(columns=['ID', 'ID2']), y_train)\n",
    "# preds_rf = rf.predict_proba(X_test.drop(columns=['ID','ID2'], axis=1))\n",
    "# y_test = pd.DataFrame(preds_rf)\n",
    "# y_test.columns = le.inverse_transform(y_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.model_selection import cross_val_score\n",
    "pbounds = {\n",
    "    'learning_rate': (0.01, 1.0),\n",
    "    'n_estimators': (100, 1000),\n",
    "    'max_depth': (3,10),\n",
    "    'subsample': (1.0, 1.0),  # Change for big datasets\n",
    "    'colsample': (1.0, 1.0),  # Change for datasets with lots of features\n",
    "    'gamma': (0, 5),\n",
    "}\n",
    "def xgboost_hyper_param(learning_rate,\n",
    "                        n_estimators,\n",
    "                        max_depth,\n",
    "                        subsample,\n",
    "                        colsample,\n",
    "                        gamma):\n",
    "    max_depth = int(max_depth)\n",
    "    n_estimators = int(n_estimators)\n",
    "    clf = XGBClassifier(\n",
    "        max_depth=max_depth,\n",
    "        learning_rate=learning_rate,\n",
    "        n_estimators=n_estimators,\n",
    "        gamma=gamma,\n",
    "        )\n",
    "    return np.mean(cross_val_score(clf, X_train.drop(columns=['ID', 'ID2'], axis=1), y_train, cv=3))\n",
    "optimizer = BayesianOptimization(\n",
    "    f=xgboost_hyper_param,\n",
    "    pbounds=pbounds,\n",
    "    random_state=1,\n",
    ")\n",
    "\n",
    "optimizer.maximize(init_points=3,n_iter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## XGboost\n",
    "\n",
    "xgb_cl = XGBClassifier(\n",
    "        max_depth=10,\n",
    "        learning_rate=0.1719,\n",
    "        n_estimators=630,\n",
    "        gamma=2.208)\n",
    "xgb_cl.fit(X_train.drop(columns=['ID', 'ID2']),y_train)\n",
    "preds_xgb = xgb_cl.predict_proba(X_test.drop(columns=['ID','ID2'], axis=1))\n",
    "y_test = pd.DataFrame(preds_xgb)\n",
    "y_test.columns = le.inverse_transform(y_test.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W7NYpdx0nc4s"
   },
   "source": [
    "### Submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "H8VHTNphyCDC",
    "outputId": "462812c6-d47a-4720-eaef-7d74240e2484"
   },
   "outputs": [],
   "source": [
    "answer_mass = []\n",
    "for i in range(X_test.shape[0]):\n",
    "    id = X_test['ID'].iloc[i]\n",
    "    for c in y_test.columns:\n",
    "        answer_mass.append([id + ' X ' + c, y_test[c].iloc[i]])\n",
    "\n",
    "df_answer = pd.DataFrame(answer_mass)\n",
    "df_answer.columns = ['ID X PCODE', 'Label']\n",
    "for i in range(df_answer.shape[0]):\n",
    "    if df_answer['ID X PCODE'].iloc[i] in true_values:\n",
    "        df_answer['Label'].iloc[i] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zgIYeYwzzP1B"
   },
   "outputs": [],
   "source": [
    "df_answer.reset_index(drop=True, inplace=True)\n",
    "df_answer.to_csv('submission12.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1ZTTmnHMmev1"
   },
   "source": [
    "Submit"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Baseline1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
