{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Tixonmavrin/Zindi-Zimnat-Insurance-Recommendation-Challenge/blob/master/Baseline1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QfCbUjWSgMTJ"
   },
   "source": [
    "##Zimnat Insurance Recommendation Challenge\n",
    "Can you predict which insurance products existing clients will want next?\n",
    "###Baseline with catboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "82PpxfmqglcE"
   },
   "source": [
    "### Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3arOHSJwCtNq"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, ExtraTreesClassifier, VotingClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, RandomizedSearchCV, StratifiedShuffleSplit\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import uniform as sp_randFloat\n",
    "from scipy.stats import randint as sp_randInt\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "import pprint\n",
    "import joblib\n",
    "from sklearn.model_selection import KFold\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.metrics import log_loss\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from scipy.optimize import minimize\n",
    "# Classifiers\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "# Model selection\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "# Skopt functions\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.callbacks import DeadlineStopper, VerboseCallback, DeltaXStopper\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s3ZCXtzKDiDe"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('Train.csv')\n",
    "test = pd.read_csv('Test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YfPBoU_FUxtO"
   },
   "source": [
    "# New Section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o_ELVeoVgv3v"
   },
   "source": [
    "### New format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oxjj_QAfEyZw"
   },
   "outputs": [],
   "source": [
    "X_train = []\n",
    "X_train_columns = train.columns\n",
    "c = 0\n",
    "for v in train.values:\n",
    "    info = v[:8]\n",
    "    binary = v[8:]\n",
    "    index = [k for k, i in enumerate(binary) if i == 1]\n",
    "    for i in index:\n",
    "        c+=1\n",
    "        for k in range(len(binary)):\n",
    "            if k == i:\n",
    "                binary_transformed = list(copy.copy(binary))\n",
    "                binary_transformed[i] = 0\n",
    "                X_train.append(list(info) + binary_transformed + [X_train_columns[8+k]] + [c])\n",
    "\n",
    "X_train = pd.DataFrame(X_train)\n",
    "X_train.columns = ['ID', 'join_date', 'sex', 'marital_status', 'birth_year', 'branch_code',\n",
    "       'occupation_code', 'occupation_category_code', 'P5DA', 'RIBP', '8NN1',\n",
    "       '7POT', '66FJ', 'GYSR', 'SOP4', 'RVSZ', 'PYUQ', 'LJR9', 'N2MW', 'AHXO',\n",
    "       'BSTQ', 'FM3X', 'K6QO', 'QBOL', 'JWFN', 'JZ9D', 'J9JW', 'GHYX', 'ECY3', 'product_pred', 'ID2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "URdSMgJeOnLE"
   },
   "outputs": [],
   "source": [
    "X_test = []\n",
    "true_values = []\n",
    "c = 0\n",
    "for v in test.values:\n",
    "    c += 1\n",
    "    info = v[:8]\n",
    "    binary = v[8:]\n",
    "    index = [k for k, i in enumerate(binary) if i == 1]\n",
    "    X_test.append(list(info) + list(binary) + [c])\n",
    "    for k in test.columns[8:][index]:\n",
    "        true_values.append(v[0] + ' X ' + k)\n",
    "\n",
    "X_test = pd.DataFrame(X_test)\n",
    "X_test.columns = ['ID', 'join_date', 'sex', 'marital_status', 'birth_year', 'branch_code',\n",
    "       'occupation_code', 'occupation_category_code', 'P5DA', 'RIBP', '8NN1',\n",
    "       '7POT', '66FJ', 'GYSR', 'SOP4', 'RVSZ', 'PYUQ', 'LJR9', 'N2MW', 'AHXO',\n",
    "       'BSTQ', 'FM3X', 'K6QO', 'QBOL', 'JWFN', 'JZ9D', 'J9JW', 'GHYX', 'ECY3', 'ID2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s1KcI9I6g1de"
   },
   "source": [
    "### Transform data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ttUKNdnAczTd"
   },
   "outputs": [],
   "source": [
    "features_train = []\n",
    "features_test = []\n",
    "columns = []\n",
    "\n",
    "append_features = ['P5DA', 'RIBP', '8NN1', '7POT', '66FJ', 'GYSR', 'SOP4', 'RVSZ', 'PYUQ', 'LJR9', \n",
    "'N2MW', 'AHXO','BSTQ', 'FM3X', 'K6QO', 'QBOL', 'JWFN', 'JZ9D', 'J9JW', 'GHYX', \n",
    "'ECY3', 'ID', 'ID2', 'join_date', 'sex', 'marital_status', 'branch_code', 'occupation_code', 'occupation_category_code',\n",
    "'birth_year']\n",
    "for v in append_features:\n",
    "    features_train.append(X_train[v].values.reshape(-1, 1))\n",
    "    features_test.append(X_test[v].values.reshape(-1, 1))\n",
    "    columns.append(np.array([v]))\n",
    "\n",
    "y_train = X_train[['product_pred']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kWCK5LrfkPp-"
   },
   "outputs": [],
   "source": [
    "features_train = np.concatenate(features_train, axis=1)\n",
    "features_test = np.concatenate(features_test, axis=1)\n",
    "columns = np.concatenate(np.array(columns))\n",
    "\n",
    "X_train = pd.DataFrame(features_train)\n",
    "X_train.columns = columns\n",
    "X_test = pd.DataFrame(features_test)\n",
    "X_test.columns = columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YVUKKo3llI0y"
   },
   "source": [
    "### New features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NhfA7yullH76"
   },
   "outputs": [],
   "source": [
    "X_train['date1'] = X_train['join_date'].apply(lambda x: int(x.split('/')[0]) if (x == x) else np.nan)\n",
    "X_train['date2'] = X_train['join_date'].apply(lambda x: int(x.split('/')[1]) if (x == x) else np.nan)\n",
    "X_train['date3'] = X_train['join_date'].apply(lambda x: int(x.split('/')[2]) if (x == x) else np.nan)\n",
    "X_train.drop('join_date', axis=1, inplace=True)\n",
    "\n",
    "X_test['date1'] = X_test['join_date'].apply(lambda x: int(x.split('/')[0]) if (x == x) else np.nan)\n",
    "X_test['date2'] = X_test['join_date'].apply(lambda x: int(x.split('/')[1]) if (x == x) else np.nan)\n",
    "X_test['date3'] = X_test['join_date'].apply(lambda x: int(x.split('/')[2]) if (x == x) else np.nan)\n",
    "X_test.drop('join_date', axis=1, inplace=True)\n",
    "\n",
    "X_train['date_diff'] = X_train['date3'] - X_train['birth_year']\n",
    "X_test['date_diff'] = X_test['date3'] - X_test['birth_year']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GDTy7qyulLoP"
   },
   "source": [
    "### Change types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YFf8xSoc3kN4"
   },
   "outputs": [],
   "source": [
    "X_train = X_train.fillna(0)\n",
    "X_test = X_test.fillna(0)\n",
    "y_train = y_train.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mTCyVmQjS9nv"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "data = X_train.append(X_test)\n",
    "for v in ['sex', 'marital_status', 'branch_code', 'occupation_code', 'occupation_category_code',]:\n",
    "    data.loc[:,v] = le.fit_transform(data.loc[:,v])\n",
    "X_train = data[:X_train.shape[0]]\n",
    "X_test = data[-X_test.shape[0]:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OtwJsy7ZnIuO"
   },
   "outputs": [],
   "source": [
    "le.fit(y_train.iloc[:,0])\n",
    "y_train = pd.DataFrame(le.transform(y_train.iloc[:,0]))\n",
    "y_train.columns = ['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "colab_type": "code",
    "id": "O6YV-YYjUdA8",
    "outputId": "7c1375d0-b88b-4dd1-d893-1aa34c5173c8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>join_date</th>\n",
       "      <th>sex</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>birth_year</th>\n",
       "      <th>branch_code</th>\n",
       "      <th>occupation_code</th>\n",
       "      <th>occupation_category_code</th>\n",
       "      <th>P5DA</th>\n",
       "      <th>RIBP</th>\n",
       "      <th>8NN1</th>\n",
       "      <th>7POT</th>\n",
       "      <th>66FJ</th>\n",
       "      <th>GYSR</th>\n",
       "      <th>SOP4</th>\n",
       "      <th>RVSZ</th>\n",
       "      <th>PYUQ</th>\n",
       "      <th>LJR9</th>\n",
       "      <th>N2MW</th>\n",
       "      <th>AHXO</th>\n",
       "      <th>BSTQ</th>\n",
       "      <th>FM3X</th>\n",
       "      <th>K6QO</th>\n",
       "      <th>QBOL</th>\n",
       "      <th>JWFN</th>\n",
       "      <th>JZ9D</th>\n",
       "      <th>J9JW</th>\n",
       "      <th>GHYX</th>\n",
       "      <th>ECY3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4WKQSBB</td>\n",
       "      <td>1/2/2019</td>\n",
       "      <td>F</td>\n",
       "      <td>M</td>\n",
       "      <td>1987</td>\n",
       "      <td>1X1H</td>\n",
       "      <td>2A7I</td>\n",
       "      <td>T4MS</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CP5S02H</td>\n",
       "      <td>1/6/2019</td>\n",
       "      <td>F</td>\n",
       "      <td>M</td>\n",
       "      <td>1981</td>\n",
       "      <td>UAOD</td>\n",
       "      <td>2A7I</td>\n",
       "      <td>T4MS</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2YKDILJ</td>\n",
       "      <td>1/6/2013</td>\n",
       "      <td>M</td>\n",
       "      <td>U</td>\n",
       "      <td>1991</td>\n",
       "      <td>748L</td>\n",
       "      <td>QZYX</td>\n",
       "      <td>90QI</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2S9E81J</td>\n",
       "      <td>1/8/2019</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>1990</td>\n",
       "      <td>1X1H</td>\n",
       "      <td>BP09</td>\n",
       "      <td>56SI</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BHDYVFT</td>\n",
       "      <td>1/8/2019</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>1990</td>\n",
       "      <td>748L</td>\n",
       "      <td>NO3L</td>\n",
       "      <td>T4MS</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID join_date sex marital_status  birth_year branch_code  \\\n",
       "0  4WKQSBB  1/2/2019   F              M        1987        1X1H   \n",
       "1  CP5S02H  1/6/2019   F              M        1981        UAOD   \n",
       "2  2YKDILJ  1/6/2013   M              U        1991        748L   \n",
       "3  2S9E81J  1/8/2019   M              M        1990        1X1H   \n",
       "4  BHDYVFT  1/8/2019   M              M        1990        748L   \n",
       "\n",
       "  occupation_code occupation_category_code  P5DA  RIBP  8NN1  7POT  66FJ  \\\n",
       "0            2A7I                     T4MS     0     0     0     0     0   \n",
       "1            2A7I                     T4MS     0     0     0     0     0   \n",
       "2            QZYX                     90QI     0     0     0     0     0   \n",
       "3            BP09                     56SI     0     0     0     0     0   \n",
       "4            NO3L                     T4MS     0     0     0     0     0   \n",
       "\n",
       "   GYSR  SOP4  RVSZ  PYUQ  LJR9  N2MW  AHXO  BSTQ  FM3X  K6QO  QBOL  JWFN  \\\n",
       "0     0     0     1     0     0     0     0     0     0     1     0     0   \n",
       "1     0     0     1     0     0     0     0     0     0     1     0     0   \n",
       "2     0     1     1     0     0     0     0     0     0     0     0     0   \n",
       "3     0     0     1     0     0     0     0     0     0     1     0     0   \n",
       "4     0     0     0     0     0     0     0     0     0     0     0     0   \n",
       "\n",
       "   JZ9D  J9JW  GHYX  ECY3  \n",
       "0     0     0     0     0  \n",
       "1     0     0     0     0  \n",
       "2     0     0     0     1  \n",
       "3     0     0     0     0  \n",
       "4     1     1     0     0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "colab_type": "code",
    "id": "n1keGpNvUdBB",
    "outputId": "cde619f7-73ad-48b8-9888-09ec547865af"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P5DA</th>\n",
       "      <th>RIBP</th>\n",
       "      <th>8NN1</th>\n",
       "      <th>7POT</th>\n",
       "      <th>66FJ</th>\n",
       "      <th>GYSR</th>\n",
       "      <th>SOP4</th>\n",
       "      <th>RVSZ</th>\n",
       "      <th>PYUQ</th>\n",
       "      <th>LJR9</th>\n",
       "      <th>N2MW</th>\n",
       "      <th>AHXO</th>\n",
       "      <th>BSTQ</th>\n",
       "      <th>FM3X</th>\n",
       "      <th>K6QO</th>\n",
       "      <th>QBOL</th>\n",
       "      <th>JWFN</th>\n",
       "      <th>JZ9D</th>\n",
       "      <th>J9JW</th>\n",
       "      <th>GHYX</th>\n",
       "      <th>ECY3</th>\n",
       "      <th>ID</th>\n",
       "      <th>ID2</th>\n",
       "      <th>sex</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>branch_code</th>\n",
       "      <th>occupation_code</th>\n",
       "      <th>occupation_category_code</th>\n",
       "      <th>birth_year</th>\n",
       "      <th>date1</th>\n",
       "      <th>date2</th>\n",
       "      <th>date3</th>\n",
       "      <th>date_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4WKQSBB</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "      <td>1987</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4WKQSBB</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "      <td>1987</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>CP5S02H</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "      <td>1981</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>CP5S02H</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "      <td>1981</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2YKDILJ</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>185</td>\n",
       "      <td>1</td>\n",
       "      <td>1991</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   P5DA  RIBP  8NN1  7POT  66FJ  GYSR  SOP4  RVSZ  PYUQ  LJR9  N2MW  AHXO  \\\n",
       "0     0     0     0     0     0     0     0     0     0     0     0     0   \n",
       "1     0     0     0     0     0     0     0     1     0     0     0     0   \n",
       "2     0     0     0     0     0     0     0     0     0     0     0     0   \n",
       "3     0     0     0     0     0     0     0     1     0     0     0     0   \n",
       "4     0     0     0     0     0     0     0     1     0     0     0     0   \n",
       "\n",
       "   BSTQ  FM3X  K6QO  QBOL  JWFN  JZ9D  J9JW  GHYX  ECY3       ID  ID2  sex  \\\n",
       "0     0     0     1     0     0     0     0     0     0  4WKQSBB    1    0   \n",
       "1     0     0     0     0     0     0     0     0     0  4WKQSBB    2    0   \n",
       "2     0     0     1     0     0     0     0     0     0  CP5S02H    3    0   \n",
       "3     0     0     0     0     0     0     0     0     0  CP5S02H    4    0   \n",
       "4     0     0     0     0     0     0     0     0     1  2YKDILJ    5    1   \n",
       "\n",
       "   marital_status  branch_code  occupation_code  occupation_category_code  \\\n",
       "0               2            0               19                         5   \n",
       "1               2            0               19                         5   \n",
       "2               2           11               19                         5   \n",
       "3               2           11               19                         5   \n",
       "4               6            3              185                         1   \n",
       "\n",
       "   birth_year  date1  date2   date3  date_diff  \n",
       "0        1987    1.0    2.0  2019.0       32.0  \n",
       "1        1987    1.0    2.0  2019.0       32.0  \n",
       "2        1981    1.0    6.0  2019.0       38.0  \n",
       "3        1981    1.0    6.0  2019.0       38.0  \n",
       "4        1991    1.0    6.0  2013.0       22.0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I1bnMA4jclg3"
   },
   "outputs": [],
   "source": [
    "data = X_train.append(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2YZCWNJDcrLh"
   },
   "outputs": [],
   "source": [
    "freq_1 = data['marital_status'].value_counts()\n",
    "data['marital_status_fe'] = data['marital_status'].map(freq_1)\n",
    "\n",
    "freq_2 = data['branch_code'].value_counts()\n",
    "data['branch_code_fe'] = data['branch_code'].map(freq_2)\n",
    "\n",
    "freq_3 = data['occupation_category_code'].value_counts()\n",
    "data['occupation_category_code_fe'] = data['occupation_category_code'].map(freq_3)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wHlpss7Xd_ng"
   },
   "outputs": [],
   "source": [
    "## Squaring the features \n",
    "\n",
    "data['marital_status_sq'] = data['marital_status']**2\n",
    "data['branch_code_sq'] = data['branch_code']**2\n",
    "data['occupation_code_sq'] = data['occupation_code']**2\n",
    "data['occupation_category_code_sq'] = data['occupation_category_code']**2\n",
    "data['date_diff_sq'] = data['date_diff']**2\n",
    "\n",
    "data['marital_status_cube'] = data['marital_status']**3\n",
    "data['branch_code_cube'] = data['branch_code']**3\n",
    "data['occupation_code_cube'] = data['occupation_code']**3\n",
    "data['occupation_category_code_cube'] = data['occupation_category_code']**3\n",
    "data['date_diff_cube'] = data['date_diff']**3\n",
    "\n",
    "data['marital_status_log'] = (data['marital_status']+1).transform(np.log)\n",
    "data['branch_code_log'] = (data['branch_code']+1).transform(np.log)\n",
    "data['occupation_code_cube'] = (data['occupation_code']+1).transform(np.log)\n",
    "data['occupation_category_code_log'] = (data['occupation_category_code']+1).transform(np.log)\n",
    "data['date_diff_log'] = (data['date_diff']+1).transform(np.log)\n",
    "\n",
    "data['sex*marital_status'] = data['sex'] * data['marital_status']\n",
    "data['occupation_code*occupation_cat_code'] = data['occupation_code'] * data['occupation_category_code']\n",
    "# data = data.drop(['marital_status', 'branch_code', 'occupation_category_code'], axis=1)\n",
    "# X_train = data[:X_train.shape[0]]\n",
    "# X_test = data[-X_test.shape[0]:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "colab_type": "code",
    "id": "rez51Ia-et-I",
    "outputId": "c21fd0c2-ddcc-41a3-b9b1-bfdbbd15c247"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P5DA</th>\n",
       "      <th>RIBP</th>\n",
       "      <th>8NN1</th>\n",
       "      <th>7POT</th>\n",
       "      <th>66FJ</th>\n",
       "      <th>GYSR</th>\n",
       "      <th>SOP4</th>\n",
       "      <th>RVSZ</th>\n",
       "      <th>PYUQ</th>\n",
       "      <th>LJR9</th>\n",
       "      <th>N2MW</th>\n",
       "      <th>AHXO</th>\n",
       "      <th>BSTQ</th>\n",
       "      <th>FM3X</th>\n",
       "      <th>K6QO</th>\n",
       "      <th>QBOL</th>\n",
       "      <th>JWFN</th>\n",
       "      <th>JZ9D</th>\n",
       "      <th>J9JW</th>\n",
       "      <th>GHYX</th>\n",
       "      <th>ECY3</th>\n",
       "      <th>ID</th>\n",
       "      <th>ID2</th>\n",
       "      <th>sex</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>branch_code</th>\n",
       "      <th>occupation_code</th>\n",
       "      <th>occupation_category_code</th>\n",
       "      <th>birth_year</th>\n",
       "      <th>date1</th>\n",
       "      <th>date2</th>\n",
       "      <th>date3</th>\n",
       "      <th>date_diff</th>\n",
       "      <th>marital_status_fe</th>\n",
       "      <th>branch_code_fe</th>\n",
       "      <th>occupation_category_code_fe</th>\n",
       "      <th>marital_status_sq</th>\n",
       "      <th>branch_code_sq</th>\n",
       "      <th>occupation_code_sq</th>\n",
       "      <th>occupation_category_code_sq</th>\n",
       "      <th>date_diff_sq</th>\n",
       "      <th>marital_status_cube</th>\n",
       "      <th>branch_code_cube</th>\n",
       "      <th>occupation_code_cube</th>\n",
       "      <th>occupation_category_code_cube</th>\n",
       "      <th>date_diff_cube</th>\n",
       "      <th>marital_status_log</th>\n",
       "      <th>branch_code_log</th>\n",
       "      <th>occupation_category_code_log</th>\n",
       "      <th>date_diff_log</th>\n",
       "      <th>sex*marital_status</th>\n",
       "      <th>occupation_code*occupation_cat_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4WKQSBB</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "      <td>1987</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>59731</td>\n",
       "      <td>3130</td>\n",
       "      <td>48918</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>361</td>\n",
       "      <td>25</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>2.995732</td>\n",
       "      <td>125</td>\n",
       "      <td>32768.0</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>3.496508</td>\n",
       "      <td>0</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4WKQSBB</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "      <td>1987</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>59731</td>\n",
       "      <td>3130</td>\n",
       "      <td>48918</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>361</td>\n",
       "      <td>25</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>2.995732</td>\n",
       "      <td>125</td>\n",
       "      <td>32768.0</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>3.496508</td>\n",
       "      <td>0</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>CP5S02H</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "      <td>1981</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>59731</td>\n",
       "      <td>8972</td>\n",
       "      <td>48918</td>\n",
       "      <td>4</td>\n",
       "      <td>121</td>\n",
       "      <td>361</td>\n",
       "      <td>25</td>\n",
       "      <td>1444.0</td>\n",
       "      <td>8</td>\n",
       "      <td>1331</td>\n",
       "      <td>2.995732</td>\n",
       "      <td>125</td>\n",
       "      <td>54872.0</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>2.484907</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>3.663562</td>\n",
       "      <td>0</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>CP5S02H</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "      <td>1981</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>59731</td>\n",
       "      <td>8972</td>\n",
       "      <td>48918</td>\n",
       "      <td>4</td>\n",
       "      <td>121</td>\n",
       "      <td>361</td>\n",
       "      <td>25</td>\n",
       "      <td>1444.0</td>\n",
       "      <td>8</td>\n",
       "      <td>1331</td>\n",
       "      <td>2.995732</td>\n",
       "      <td>125</td>\n",
       "      <td>54872.0</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>2.484907</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>3.663562</td>\n",
       "      <td>0</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2YKDILJ</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>185</td>\n",
       "      <td>1</td>\n",
       "      <td>1991</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>6905</td>\n",
       "      <td>21481</td>\n",
       "      <td>14842</td>\n",
       "      <td>36</td>\n",
       "      <td>9</td>\n",
       "      <td>34225</td>\n",
       "      <td>1</td>\n",
       "      <td>484.0</td>\n",
       "      <td>216</td>\n",
       "      <td>27</td>\n",
       "      <td>5.225747</td>\n",
       "      <td>1</td>\n",
       "      <td>10648.0</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>3.135494</td>\n",
       "      <td>6</td>\n",
       "      <td>185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   P5DA  RIBP  8NN1  7POT  66FJ  GYSR  SOP4  RVSZ  PYUQ  LJR9  N2MW  AHXO  \\\n",
       "0     0     0     0     0     0     0     0     0     0     0     0     0   \n",
       "1     0     0     0     0     0     0     0     1     0     0     0     0   \n",
       "2     0     0     0     0     0     0     0     0     0     0     0     0   \n",
       "3     0     0     0     0     0     0     0     1     0     0     0     0   \n",
       "4     0     0     0     0     0     0     0     1     0     0     0     0   \n",
       "\n",
       "   BSTQ  FM3X  K6QO  QBOL  JWFN  JZ9D  J9JW  GHYX  ECY3       ID  ID2  sex  \\\n",
       "0     0     0     1     0     0     0     0     0     0  4WKQSBB    1    0   \n",
       "1     0     0     0     0     0     0     0     0     0  4WKQSBB    2    0   \n",
       "2     0     0     1     0     0     0     0     0     0  CP5S02H    3    0   \n",
       "3     0     0     0     0     0     0     0     0     0  CP5S02H    4    0   \n",
       "4     0     0     0     0     0     0     0     0     1  2YKDILJ    5    1   \n",
       "\n",
       "   marital_status  branch_code  occupation_code  occupation_category_code  \\\n",
       "0               2            0               19                         5   \n",
       "1               2            0               19                         5   \n",
       "2               2           11               19                         5   \n",
       "3               2           11               19                         5   \n",
       "4               6            3              185                         1   \n",
       "\n",
       "   birth_year  date1  date2   date3  date_diff  marital_status_fe  \\\n",
       "0        1987    1.0    2.0  2019.0       32.0              59731   \n",
       "1        1987    1.0    2.0  2019.0       32.0              59731   \n",
       "2        1981    1.0    6.0  2019.0       38.0              59731   \n",
       "3        1981    1.0    6.0  2019.0       38.0              59731   \n",
       "4        1991    1.0    6.0  2013.0       22.0               6905   \n",
       "\n",
       "   branch_code_fe  occupation_category_code_fe  marital_status_sq  \\\n",
       "0            3130                        48918                  4   \n",
       "1            3130                        48918                  4   \n",
       "2            8972                        48918                  4   \n",
       "3            8972                        48918                  4   \n",
       "4           21481                        14842                 36   \n",
       "\n",
       "   branch_code_sq  occupation_code_sq  occupation_category_code_sq  \\\n",
       "0               0                 361                           25   \n",
       "1               0                 361                           25   \n",
       "2             121                 361                           25   \n",
       "3             121                 361                           25   \n",
       "4               9               34225                            1   \n",
       "\n",
       "   date_diff_sq  marital_status_cube  branch_code_cube  occupation_code_cube  \\\n",
       "0        1024.0                    8                 0              2.995732   \n",
       "1        1024.0                    8                 0              2.995732   \n",
       "2        1444.0                    8              1331              2.995732   \n",
       "3        1444.0                    8              1331              2.995732   \n",
       "4         484.0                  216                27              5.225747   \n",
       "\n",
       "   occupation_category_code_cube  date_diff_cube  marital_status_log  \\\n",
       "0                            125         32768.0            1.098612   \n",
       "1                            125         32768.0            1.098612   \n",
       "2                            125         54872.0            1.098612   \n",
       "3                            125         54872.0            1.098612   \n",
       "4                              1         10648.0            1.945910   \n",
       "\n",
       "   branch_code_log  occupation_category_code_log  date_diff_log  \\\n",
       "0         0.000000                      1.791759       3.496508   \n",
       "1         0.000000                      1.791759       3.496508   \n",
       "2         2.484907                      1.791759       3.663562   \n",
       "3         2.484907                      1.791759       3.663562   \n",
       "4         1.386294                      0.693147       3.135494   \n",
       "\n",
       "   sex*marital_status  occupation_code*occupation_cat_code  \n",
       "0                   0                                   95  \n",
       "1                   0                                   95  \n",
       "2                   0                                   95  \n",
       "3                   0                                   95  \n",
       "4                   6                                  185  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mlPf0er-Nxzh"
   },
   "outputs": [],
   "source": [
    "X_train = data[:X_train.shape[0]]\n",
    "X_test = data[-X_test.shape[0]:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.concat([X_train, y_train], axis=1)\n",
    "labels = train['target']\n",
    "train = train.drop(['ID', 'ID2', 'target'],axis=1)\n",
    "# print(train.head())\n",
    "\n",
    "## we need a test set that we didn't train on to find the best weights for combining the classifiers\n",
    "# sss = StratifiedShuffleSplit(labels, test_size=0.05, random_state=1234)\n",
    "# for train_index, test_index in sss:\n",
    "#     break\n",
    "\n",
    "    \n",
    "cv = StratifiedShuffleSplit(n_splits=10, random_state=42)\n",
    "\n",
    "for train_idx, test_idx in cv.split(train, labels):\n",
    "    break\n",
    "train_x, train_y = train.values[train_idx], labels.values[train_idx]\n",
    "test_x, test_y = train.values[test_idx], labels.values[test_idx]\n",
    "# labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59717, 50)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFC LogLoss 1.2471173670781892\n",
      "LogisticRegression LogLoss 1.6737262787055527\n",
      "RFC2 LogLoss 1.2504952893686287\n",
      "Ensamble Score: 0.5645719152388188\n",
      "Best Weights: [0.46307283 0.03022894 0.50669823]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "### building the classifiers\n",
    "clfs = []\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=50, random_state=4141, n_jobs=-1)\n",
    "rfc.fit(train_x, train_y)\n",
    "print('RFC LogLoss {score}'.format(score=log_loss(test_y, rfc.predict_proba(test_x),  labels=rfc.classes_)))\n",
    "clfs.append(rfc)\n",
    "\n",
    "### usually you'd use xgboost and neural nets here\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(train_x, train_y)\n",
    "print('LogisticRegression LogLoss {score}'.format(score=log_loss(test_y, logreg.predict_proba(test_x),  labels=rfc.classes_)))\n",
    "clfs.append(logreg)\n",
    "\n",
    "rfc2 = RandomForestClassifier(n_estimators=50, random_state=1337, n_jobs=-1)\n",
    "rfc2.fit(train_x, train_y)\n",
    "print('RFC2 LogLoss {score}'.format(score=log_loss(test_y, rfc2.predict_proba(test_x),  labels=rfc.classes_)))\n",
    "clfs.append(rfc2)\n",
    "\n",
    "\n",
    "### finding the optimum weights\n",
    "\n",
    "predictions = []\n",
    "for clf in clfs:\n",
    "    predictions.append(clf.predict_proba(test_x))\n",
    "classes = rfc.classes_\n",
    "def log_loss_func(weights):\n",
    "    ''' scipy minimize will pass the weights as a numpy array '''\n",
    "    final_prediction = 0\n",
    "    for weight, prediction in zip(weights, predictions):\n",
    "            final_prediction += weight*prediction\n",
    "\n",
    "    return log_loss(test_y, final_prediction, labels=classes)\n",
    "    \n",
    "#the algorithms need a starting value, right not we chose 0.5 for all weights\n",
    "#its better to choose many random starting points and run minimize a few times\n",
    "starting_values = [0.5]*len(predictions)\n",
    "\n",
    "#adding constraints  and a different solver as suggested by user 16universe\n",
    "#https://kaggle2.blob.core.windows.net/forum-message-attachments/75655/2393/otto%20model%20weights.pdf?sv=2012-02-12&se=2015-05-03T21%3A22%3A17Z&sr=b&sp=r&sig=rkeA7EJC%2BiQ%2FJ%2BcMpcA4lYQLFh6ubNqs2XAkGtFsAv0%3D\n",
    "cons = ({'type':'eq','fun':lambda w: 1-sum(w)})\n",
    "#our weights are bound between 0 and 1\n",
    "bounds = [(0,1)]*len(predictions)\n",
    "\n",
    "res = minimize(log_loss_func, starting_values, method='SLSQP', bounds=bounds, constraints=cons)\n",
    "\n",
    "print('Ensamble Score: {best_score}'.format(best_score=res['fun']))\n",
    "print('Best Weights: {weights}'.format(weights=res['x']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MegaClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, estimators, xv_tries=4, test_size=0.2):\n",
    "        self.estimators = estimators\n",
    "        self.xv_tries = xv_tries\n",
    "        self.test_size = test_size\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.X_trains = []\n",
    "        self.y_trains = []\n",
    "        self.X_valids = []\n",
    "        self.y_valids = []\n",
    "        for i in range(self.xv_tries):\n",
    "            Xt, Xv, yt, yv = train_test_split(X, y, test_size=self.test_size)\n",
    "            self.X_trains.append(Xt)\n",
    "            self.X_valids.append(Xv)\n",
    "            self.y_trains.append(yt)\n",
    "            self.y_valids.append(yv)\n",
    "\n",
    "        # train the classifiers\n",
    "        self.all_xv_predictions = []\n",
    "\n",
    "        for ind, Xt in enumerate(self.X_trains):\n",
    "            cur_xv_predictions = []\n",
    "            for estimator in self.estimators:\n",
    "                #new_est = copy.deepcopy(estimator)\n",
    "                #new_est.fit(Xt, self.y_trains[ind])\n",
    "                estimator.fit(Xt, self.y_trains[ind])\n",
    "                cur_xv_predictions.append(estimator.predict_proba(self.X_valids[ind]))\n",
    "            self.all_xv_predictions.append(cur_xv_predictions)\n",
    "\n",
    "        num_estimators = len(self.estimators)\n",
    "        initial_weights = [1.0 / float(num_estimators) for i in range(num_estimators)]\n",
    "\n",
    "        print (\"Optimizing....\")\n",
    "        bounds = [(0, 1) for i in range(num_estimators)]\n",
    "        constraints = {'type': 'eq', 'fun': lambda w: 1 - sum(w)}\n",
    "        res = minimize(self.__find_best_blending_weights, initial_weights, bounds=bounds, constraints=constraints)\n",
    "        self.final_weights = res.x\n",
    "        print (\"Optimization finished...\")\n",
    "\n",
    "        print (\"Weights:\")\n",
    "        print (self.final_weights)\n",
    "\n",
    "        for estimator in self.estimators:\n",
    "            estimator.fit(X, y)\n",
    "\n",
    "\n",
    "    def __find_best_blending_weights(self, weights):\n",
    "        log_losses = []\n",
    "        for ind1, xv_predictions in enumerate(self.all_xv_predictions):\n",
    "            y_final_pred_prob = None\n",
    "            for ind, est_predictions in enumerate(xv_predictions):\n",
    "                if y_final_pred_prob is None:\n",
    "                    y_final_pred_prob = weights[ind] * est_predictions\n",
    "                else:\n",
    "                    y_final_pred_prob = np.add(y_final_pred_prob, (weights[ind] * est_predictions))\n",
    "            log_losses.append(log_loss(self.y_valids[ind1], y_final_pred_prob))\n",
    "\n",
    "        log_losses = np.array(log_losses)\n",
    "        return log_losses.mean()\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "\n",
    "        y_final_pred_prob = None\n",
    "        for ind, estimator in enumerate(self.estimators):\n",
    "            y_pp_cur = estimator.predict_proba(X)\n",
    "            if y_final_pred_prob is None:\n",
    "                y_final_pred_prob = self.final_weights[ind] * y_pp_cur\n",
    "            else:\n",
    "                y_final_pred_prob = np.add(y_final_pred_prob, (self.final_weights[ind] * y_pp_cur))\n",
    "        return y_final_pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19, 20])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-77-63bfeb656622>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mC_MC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMegaClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimators\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimators\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxv_tries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mC_MC\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ID'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ID2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mmeta_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mC_MC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ID'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ID2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-73-7411835b122b>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     25\u001b[0m                 \u001b[0;31m#new_est = copy.deepcopy(estimator)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m                 \u001b[0;31m#new_est.fit(Xt, self.y_trains[ind])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_trains\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m                 \u001b[0mcur_xv_predictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_valids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_xv_predictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcur_xv_predictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/jupyter/lib/python3.6/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, callbacks)\u001b[0m\n\u001b[1;32m    822\u001b[0m                               \u001b[0mevals_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxgb_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxgb_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 824\u001b[0;31m                               callbacks=callbacks)\n\u001b[0m\u001b[1;32m    825\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    826\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb_options\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"objective\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/jupyter/lib/python3.6/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m    210\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/jupyter/lib/python3.6/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/jupyter/lib/python3.6/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1367\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n\u001b[1;32m   1368\u001b[0m                                                     \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1369\u001b[0;31m                                                     dtrain.handle))\n\u001b[0m\u001b[1;32m   1370\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1371\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_margin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "estimators = []\n",
    "estimators.append(XGBClassifier(learning_rate=0.1675, max_depth=10, gamma=1.976, n_estimators=550))\n",
    "estimators.append(XGBClassifier(max_depth=10, learning_rate=0.1675, n_estimators=450, gamma=1.9676, min_child_weight=5, colsample_bytree=1, colsample_bylevel=1, reg_alpha=1, max_delta_step=20))\n",
    "\n",
    "C_MC = MegaClassifier(estimators = estimators, xv_tries = 5)\n",
    "C_MC. fit(X_train.drop(columns=['ID', 'ID2'],axis=1), y_train)\n",
    "\n",
    "meta_probs = C_MC.predict_proba(X_test.drop(columns=['ID', 'ID2'],axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PM1inhRD0H6w"
   },
   "outputs": [],
   "source": [
    "xgb_1 = XGBClassifier(learning_rate=0.1675, max_depth=10, gamma=1.976, n_estimators=550)\n",
    "# model_xgb = xgb.fit(X_train.drop(columns=['ID', 'ID2'],axis=1), y_train)\n",
    "# preds_xgb = model_xgb.predict_proba(X_test.drop(columns=['ID', 'ID2'],axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HciomCLiYQKs"
   },
   "outputs": [],
   "source": [
    "xgb_2 = XGBClassifier(max_depth=10, learning_rate=0.1675, n_estimators=450, gamma=1.9676, min_child_weight=5, colsample_bytree=1, colsample_bylevel=1, reg_alpha=1, max_delta_step=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6vGqAsjoYQVI"
   },
   "outputs": [],
   "source": [
    "xgb_3 = XGBClassifier(max_depth=20, learning_rate=0.1675, n_estimators=550, gamma=1.7676, min_child_weight=5, colsample_bytree=1, colsample_bylevel=1, reg_alpha=1, max_delta_step=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B0eaIhPW0H6z"
   },
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=200,max_depth=8,min_samples_split=10)\n",
    "# model_rf = rf.fit(X_train.drop(columns=['ID', 'ID2'],axis=1), y_train)\n",
    "# preds_rf = model_rf.predict_proba(X_test.drop(columns=['ID', 'ID2'],axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p5oEcvwf0H61"
   },
   "outputs": [],
   "source": [
    "gbc = GradientBoostingClassifier(n_estimators=400,learning_rate=0.1,random_state=100,max_features=4 )\n",
    "# model_gbc = gbc.fit(X_train.drop(columns=['ID', 'ID2'],axis=1), y_train)\n",
    "# preds_gbc = model_gbc.predict_proba(X_test.drop(columns=['ID', 'ID2'],axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jstr3O-N0H63"
   },
   "outputs": [],
   "source": [
    "catb = CatBoostClassifier(depth=7, iterations= 79, learning_rate = 0.24800286296598373, )\n",
    "# model_catb = catb.fit(X_train.drop(columns=['ID', 'ID2'],axis=1), y_train)\n",
    "# preds_catb = model_catb.predict_proba(X_test.drop(columns=['ID', 'ID2'],axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the Keras libraries and packages\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(32, input_dim=50, activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train.drop(columns=['ID', 'ID2'],axis=1), y_train, epochs=150, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict_classes(X_test.drop(['ID', 'ID2'], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vc30iew20H65"
   },
   "outputs": [],
   "source": [
    "eclf = VotingClassifier(estimators=[('xgb_2',xgb_2),('xgb_1',xgb_1), ('xgb_3',xgb_3), ('gbc', gbc)], voting='soft', weights=[10,10,10, 2])\n",
    "model_eclf = eclf.fit(X_train.drop(columns=['ID', 'ID2'],axis=1), y_train)\n",
    "preds_voting = model_eclf.predict_proba(X_test.drop(columns=['ID', 'ID2'],axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zblBHW_i0H68"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-14b17f728457>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds_voting\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "y_test = pd.DataFrame(preds_voting)\n",
    "y_test.columns = le.inverse_transform(y_test.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qn9zHq0iqhA3"
   },
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W7NYpdx0nc4s"
   },
   "source": [
    "### Submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H8VHTNphyCDC"
   },
   "outputs": [],
   "source": [
    "answer_mass = []\n",
    "for i in range(X_test.shape[0]):\n",
    "    id = X_test['ID'].iloc[i]\n",
    "    for c in y_test.columns:\n",
    "        answer_mass.append([id + ' X ' + c, y_test[c].iloc[i]])\n",
    "\n",
    "df_answer = pd.DataFrame(answer_mass)\n",
    "df_answer.columns = ['ID X PCODE', 'Label']\n",
    "for i in range(df_answer.shape[0]):\n",
    "    if df_answer['ID X PCODE'].iloc[i] in true_values:\n",
    "        df_answer['Label'].iloc[i] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zgIYeYwzzP1B"
   },
   "outputs": [],
   "source": [
    "df_answer.reset_index(drop=True, inplace=True)\n",
    "df_answer.to_csv('submission69.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1ZTTmnHMmev1"
   },
   "source": [
    "Submit"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Model_64.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
