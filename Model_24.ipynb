{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Tixonmavrin/Zindi-Zimnat-Insurance-Recommendation-Challenge/blob/master/Baseline1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QfCbUjWSgMTJ"
   },
   "source": [
    "##Zimnat Insurance Recommendation Challenge\n",
    "Can you predict which insurance products existing clients will want next?\n",
    "###Baseline with catboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "82PpxfmqglcE"
   },
   "source": [
    "### Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3arOHSJwCtNq"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "import sklearn\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import uniform as sp_randFloat\n",
    "from scipy.stats import randint as sp_randInt\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "import pprint\n",
    "import joblib\n",
    "from xgboost.sklearn import XGBClassifier \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Classifiers\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# Model selection\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "# Skopt functions\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.callbacks import DeadlineStopper, VerboseCallback, DeltaXStopper\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s3ZCXtzKDiDe"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('Train.csv')\n",
    "test = pd.read_csv('Test.csv')\n",
    "submission = pd.read_csv('SampleSubmission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o_ELVeoVgv3v"
   },
   "source": [
    "### New format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oxjj_QAfEyZw"
   },
   "outputs": [],
   "source": [
    "X_train = []\n",
    "X_train_columns = train.columns\n",
    "c = 0\n",
    "for v in train.values:\n",
    "    info = v[:8]\n",
    "    binary = v[8:]\n",
    "    index = [k for k, i in enumerate(binary) if i == 1]\n",
    "    for i in index:\n",
    "        c+=1\n",
    "        for k in range(len(binary)):\n",
    "            if k == i:\n",
    "                binary_transformed = list(copy.copy(binary))\n",
    "                binary_transformed[i] = 0\n",
    "                X_train.append(list(info) + binary_transformed + [X_train_columns[8+k]] + [c])\n",
    "\n",
    "X_train = pd.DataFrame(X_train)\n",
    "X_train.columns = ['ID', 'join_date', 'sex', 'marital_status', 'birth_year', 'branch_code',\n",
    "       'occupation_code', 'occupation_category_code', 'P5DA', 'RIBP', '8NN1',\n",
    "       '7POT', '66FJ', 'GYSR', 'SOP4', 'RVSZ', 'PYUQ', 'LJR9', 'N2MW', 'AHXO',\n",
    "       'BSTQ', 'FM3X', 'K6QO', 'QBOL', 'JWFN', 'JZ9D', 'J9JW', 'GHYX', 'ECY3', 'product_pred', 'ID2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "URdSMgJeOnLE"
   },
   "outputs": [],
   "source": [
    "X_test = []\n",
    "true_values = []\n",
    "c = 0\n",
    "for v in test.values:\n",
    "    c += 1\n",
    "    info = v[:8]\n",
    "    binary = v[8:]\n",
    "    index = [k for k, i in enumerate(binary) if i == 1]\n",
    "    X_test.append(list(info) + list(binary) + [c])\n",
    "    for k in test.columns[8:][index]:\n",
    "        true_values.append(v[0] + ' X ' + k)\n",
    "\n",
    "X_test = pd.DataFrame(X_test)\n",
    "X_test.columns = ['ID', 'join_date', 'sex', 'marital_status', 'birth_year', 'branch_code',\n",
    "       'occupation_code', 'occupation_category_code', 'P5DA', 'RIBP', '8NN1',\n",
    "       '7POT', '66FJ', 'GYSR', 'SOP4', 'RVSZ', 'PYUQ', 'LJR9', 'N2MW', 'AHXO',\n",
    "       'BSTQ', 'FM3X', 'K6QO', 'QBOL', 'JWFN', 'JZ9D', 'J9JW', 'GHYX', 'ECY3', 'ID2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s1KcI9I6g1de"
   },
   "source": [
    "### Transform data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ttUKNdnAczTd"
   },
   "outputs": [],
   "source": [
    "features_train = []\n",
    "features_test = []\n",
    "columns = []\n",
    "\n",
    "append_features = ['P5DA', 'RIBP', '8NN1', '7POT', '66FJ', 'GYSR', 'SOP4', 'RVSZ', 'PYUQ', 'LJR9', \n",
    "'N2MW', 'AHXO','BSTQ', 'FM3X', 'K6QO', 'QBOL', 'JWFN', 'JZ9D', 'J9JW', 'GHYX', \n",
    "'ECY3', 'ID', 'ID2', 'join_date', 'sex', 'marital_status', 'branch_code', 'occupation_code', 'occupation_category_code',\n",
    "'birth_year']\n",
    "for v in append_features:\n",
    "    features_train.append(X_train[v].values.reshape(-1, 1))\n",
    "    features_test.append(X_test[v].values.reshape(-1, 1))\n",
    "    columns.append(np.array([v]))\n",
    "\n",
    "y_train = X_train[['product_pred']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kWCK5LrfkPp-"
   },
   "outputs": [],
   "source": [
    "features_train = np.concatenate(features_train, axis=1)\n",
    "features_test = np.concatenate(features_test, axis=1)\n",
    "columns = np.concatenate(np.array(columns))\n",
    "\n",
    "X_train = pd.DataFrame(features_train)\n",
    "X_train.columns = columns\n",
    "X_test = pd.DataFrame(features_test)\n",
    "X_test.columns = columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YVUKKo3llI0y"
   },
   "source": [
    "### New features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NhfA7yullH76"
   },
   "outputs": [],
   "source": [
    "X_train['date1'] = X_train['join_date'].apply(lambda x: int(x.split('/')[0]) if (x == x) else np.nan)\n",
    "X_train['date2'] = X_train['join_date'].apply(lambda x: int(x.split('/')[1]) if (x == x) else np.nan)\n",
    "X_train['date3'] = X_train['join_date'].apply(lambda x: int(x.split('/')[2]) if (x == x) else np.nan)\n",
    "X_train.drop('join_date', axis=1, inplace=True)\n",
    "\n",
    "X_test['date1'] = X_test['join_date'].apply(lambda x: int(x.split('/')[0]) if (x == x) else np.nan)\n",
    "X_test['date2'] = X_test['join_date'].apply(lambda x: int(x.split('/')[1]) if (x == x) else np.nan)\n",
    "X_test['date3'] = X_test['join_date'].apply(lambda x: int(x.split('/')[2]) if (x == x) else np.nan)\n",
    "X_test.drop('join_date', axis=1, inplace=True)\n",
    "\n",
    "X_train['date_diff'] = X_train['date3'] - X_train['birth_year']\n",
    "X_test['date_diff'] = X_test['date3'] - X_test['birth_year']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GDTy7qyulLoP"
   },
   "source": [
    "### Change types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YFf8xSoc3kN4"
   },
   "outputs": [],
   "source": [
    "X_train = X_train.fillna(0)\n",
    "X_test = X_test.fillna(0)\n",
    "y_train = y_train.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mTCyVmQjS9nv"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "data = X_train.append(X_test)\n",
    "for v in ['sex', 'marital_status', 'branch_code', 'occupation_code', 'occupation_category_code',]:\n",
    "    data.loc[:,v] = le.fit_transform(data.loc[:,v])\n",
    "X_train = data[:X_train.shape[0]]\n",
    "X_test = data[-X_test.shape[0]:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OtwJsy7ZnIuO"
   },
   "outputs": [],
   "source": [
    "le.fit(y_train.iloc[:,0])\n",
    "y_train = pd.DataFrame(le.transform(y_train.iloc[:,0]))\n",
    "y_train.columns = ['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>join_date</th>\n",
       "      <th>sex</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>birth_year</th>\n",
       "      <th>branch_code</th>\n",
       "      <th>occupation_code</th>\n",
       "      <th>occupation_category_code</th>\n",
       "      <th>P5DA</th>\n",
       "      <th>RIBP</th>\n",
       "      <th>8NN1</th>\n",
       "      <th>7POT</th>\n",
       "      <th>66FJ</th>\n",
       "      <th>GYSR</th>\n",
       "      <th>SOP4</th>\n",
       "      <th>RVSZ</th>\n",
       "      <th>PYUQ</th>\n",
       "      <th>LJR9</th>\n",
       "      <th>N2MW</th>\n",
       "      <th>AHXO</th>\n",
       "      <th>BSTQ</th>\n",
       "      <th>FM3X</th>\n",
       "      <th>K6QO</th>\n",
       "      <th>QBOL</th>\n",
       "      <th>JWFN</th>\n",
       "      <th>JZ9D</th>\n",
       "      <th>J9JW</th>\n",
       "      <th>GHYX</th>\n",
       "      <th>ECY3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4WKQSBB</td>\n",
       "      <td>1/2/2019</td>\n",
       "      <td>F</td>\n",
       "      <td>M</td>\n",
       "      <td>1987</td>\n",
       "      <td>1X1H</td>\n",
       "      <td>2A7I</td>\n",
       "      <td>T4MS</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CP5S02H</td>\n",
       "      <td>1/6/2019</td>\n",
       "      <td>F</td>\n",
       "      <td>M</td>\n",
       "      <td>1981</td>\n",
       "      <td>UAOD</td>\n",
       "      <td>2A7I</td>\n",
       "      <td>T4MS</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2YKDILJ</td>\n",
       "      <td>1/6/2013</td>\n",
       "      <td>M</td>\n",
       "      <td>U</td>\n",
       "      <td>1991</td>\n",
       "      <td>748L</td>\n",
       "      <td>QZYX</td>\n",
       "      <td>90QI</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2S9E81J</td>\n",
       "      <td>1/8/2019</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>1990</td>\n",
       "      <td>1X1H</td>\n",
       "      <td>BP09</td>\n",
       "      <td>56SI</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BHDYVFT</td>\n",
       "      <td>1/8/2019</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>1990</td>\n",
       "      <td>748L</td>\n",
       "      <td>NO3L</td>\n",
       "      <td>T4MS</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID join_date sex marital_status  birth_year branch_code  \\\n",
       "0  4WKQSBB  1/2/2019   F              M        1987        1X1H   \n",
       "1  CP5S02H  1/6/2019   F              M        1981        UAOD   \n",
       "2  2YKDILJ  1/6/2013   M              U        1991        748L   \n",
       "3  2S9E81J  1/8/2019   M              M        1990        1X1H   \n",
       "4  BHDYVFT  1/8/2019   M              M        1990        748L   \n",
       "\n",
       "  occupation_code occupation_category_code  P5DA  RIBP  8NN1  7POT  66FJ  \\\n",
       "0            2A7I                     T4MS     0     0     0     0     0   \n",
       "1            2A7I                     T4MS     0     0     0     0     0   \n",
       "2            QZYX                     90QI     0     0     0     0     0   \n",
       "3            BP09                     56SI     0     0     0     0     0   \n",
       "4            NO3L                     T4MS     0     0     0     0     0   \n",
       "\n",
       "   GYSR  SOP4  RVSZ  PYUQ  LJR9  N2MW  AHXO  BSTQ  FM3X  K6QO  QBOL  JWFN  \\\n",
       "0     0     0     1     0     0     0     0     0     0     1     0     0   \n",
       "1     0     0     1     0     0     0     0     0     0     1     0     0   \n",
       "2     0     1     1     0     0     0     0     0     0     0     0     0   \n",
       "3     0     0     1     0     0     0     0     0     0     1     0     0   \n",
       "4     0     0     0     0     0     0     0     0     0     0     0     0   \n",
       "\n",
       "   JZ9D  J9JW  GHYX  ECY3  \n",
       "0     0     0     0     0  \n",
       "1     0     0     0     0  \n",
       "2     0     0     0     1  \n",
       "3     0     0     0     0  \n",
       "4     1     1     0     0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P5DA</th>\n",
       "      <th>RIBP</th>\n",
       "      <th>8NN1</th>\n",
       "      <th>7POT</th>\n",
       "      <th>66FJ</th>\n",
       "      <th>GYSR</th>\n",
       "      <th>SOP4</th>\n",
       "      <th>RVSZ</th>\n",
       "      <th>PYUQ</th>\n",
       "      <th>LJR9</th>\n",
       "      <th>N2MW</th>\n",
       "      <th>AHXO</th>\n",
       "      <th>BSTQ</th>\n",
       "      <th>FM3X</th>\n",
       "      <th>K6QO</th>\n",
       "      <th>QBOL</th>\n",
       "      <th>JWFN</th>\n",
       "      <th>JZ9D</th>\n",
       "      <th>J9JW</th>\n",
       "      <th>GHYX</th>\n",
       "      <th>ECY3</th>\n",
       "      <th>ID</th>\n",
       "      <th>ID2</th>\n",
       "      <th>sex</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>branch_code</th>\n",
       "      <th>occupation_code</th>\n",
       "      <th>occupation_category_code</th>\n",
       "      <th>birth_year</th>\n",
       "      <th>date1</th>\n",
       "      <th>date2</th>\n",
       "      <th>date3</th>\n",
       "      <th>date_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4WKQSBB</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "      <td>1987</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4WKQSBB</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "      <td>1987</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>CP5S02H</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "      <td>1981</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>CP5S02H</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "      <td>1981</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2YKDILJ</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>185</td>\n",
       "      <td>1</td>\n",
       "      <td>1991</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   P5DA  RIBP  8NN1  7POT  66FJ  GYSR  SOP4  RVSZ  PYUQ  LJR9  N2MW  AHXO  \\\n",
       "0     0     0     0     0     0     0     0     0     0     0     0     0   \n",
       "1     0     0     0     0     0     0     0     1     0     0     0     0   \n",
       "2     0     0     0     0     0     0     0     0     0     0     0     0   \n",
       "3     0     0     0     0     0     0     0     1     0     0     0     0   \n",
       "4     0     0     0     0     0     0     0     1     0     0     0     0   \n",
       "\n",
       "   BSTQ  FM3X  K6QO  QBOL  JWFN  JZ9D  J9JW  GHYX  ECY3       ID  ID2  sex  \\\n",
       "0     0     0     1     0     0     0     0     0     0  4WKQSBB    1    0   \n",
       "1     0     0     0     0     0     0     0     0     0  4WKQSBB    2    0   \n",
       "2     0     0     1     0     0     0     0     0     0  CP5S02H    3    0   \n",
       "3     0     0     0     0     0     0     0     0     0  CP5S02H    4    0   \n",
       "4     0     0     0     0     0     0     0     0     1  2YKDILJ    5    1   \n",
       "\n",
       "   marital_status  branch_code  occupation_code  occupation_category_code  \\\n",
       "0               2            0               19                         5   \n",
       "1               2            0               19                         5   \n",
       "2               2           11               19                         5   \n",
       "3               2           11               19                         5   \n",
       "4               6            3              185                         1   \n",
       "\n",
       "   birth_year  date1  date2   date3  date_diff  \n",
       "0        1987    1.0    2.0  2019.0       32.0  \n",
       "1        1987    1.0    2.0  2019.0       32.0  \n",
       "2        1981    1.0    6.0  2019.0       38.0  \n",
       "3        1981    1.0    6.0  2019.0       38.0  \n",
       "4        1991    1.0    6.0  2013.0       22.0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qn9zHq0iqhA3"
   },
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "kANA1SPmgfS6",
    "outputId": "78dc5019-8af1-444e-9c3e-2874c532577f"
   },
   "outputs": [],
   "source": [
    "# model = CatBoostClassifier()\n",
    "# parameters = {'depth'         : sp_randInt(4, 10),\n",
    "#               'learning_rate' : sp_randFloat(),\n",
    "#               'iterations'    : sp_randInt(10, 100)\n",
    "#              }\n",
    "\n",
    "# randm = RandomizedSearchCV(estimator=model, param_distributions = parameters,\n",
    "#                            cv = 2, n_iter = 10, n_jobs=-1)\n",
    "# randm.fit(X_train.drop(columns=['ID', 'ID2']), y_train, cat_features=['sex','marital_status','branch_code','occupation_code','occupation_category_code'])\n",
    "\n",
    "# # Results from Random Search\n",
    "# print(\"\\n========================================================\")\n",
    "# print(\" Results from Random Search \" )\n",
    "# print(\"========================================================\")\n",
    "# print(\"\\n The best estimator across ALL searched params:\\n\",randm.best_estimator_)\n",
    "# print(\"\\n The best score across ALL searched params:\\n\",randm.best_score_)\n",
    "# print(\"\\n The best parameters across ALL searched params:\\n\",randm.best_params_)\n",
    "# print(\"\\n ========================================================\")\n",
    "# model = CatBoostClassifier()\n",
    "# model.fit(X_train.drop(columns=['ID', 'ID2']), y_train, cat_features=['sex','marital_status','branch_code','occupation_code','occupation_category_code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = CatBoostClassifier(depth= 7, iterations= 79, learning_rate= 0.24800286296598373)\n",
    "# model.fit(X_train.drop(columns=['ID', 'ID2']), y_train, cat_features=['sex','marital_status','branch_code','occupation_code','occupation_category_code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def report_perf(optimizer, X, y, title, callbacks=None):\n",
    "#     \"\"\"\n",
    "#     A wrapper for measuring time and performances of different optmizers\n",
    "    \n",
    "#     optimizer = a sklearn or a skopt optimizer\n",
    "#     X = the training set \n",
    "#     y = our target\n",
    "#     title = a string label for the experiment\n",
    "#     \"\"\"\n",
    "#     start = time()\n",
    "#     if callbacks:\n",
    "#         optimizer.fit(X, y, callback=callbacks, cat_features=['sex','marital_status','branch_code','occupation_code','occupation_category_code'])\n",
    "#     else:\n",
    "#         optimizer.fit(X, y, cat_features=['sex','marital_status','branch_code','occupation_code','occupation_category_code'])\n",
    "#     d=pd.DataFrame(optimizer.cv_results_)\n",
    "#     best_score = optimizer.best_score_\n",
    "#     best_score_std = d.iloc[optimizer.best_index_].std_test_score\n",
    "#     best_params = optimizer.best_params_\n",
    "#     print((title + \" took %.2f seconds,  candidates checked: %d, best CV score: %.3f \"\n",
    "#            +u\"\\u00B1\"+\" %.3f\") % (time() - start, \n",
    "#                                   len(optimizer.cv_results_['params']),\n",
    "#                                   best_score,\n",
    "#                                   best_score_std))    \n",
    "#     print('Best parameters:')\n",
    "#     pprint.pprint(best_params)\n",
    "#     print()\n",
    "#     return best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# roc_auc = make_scorer(roc_auc_score, greater_is_better=True, needs_threshold=True)\n",
    "# skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf = CatBoostClassifier(cat_features=['sex','marital_status','branch_code','occupation_code','occupation_category_code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search_spaces = {'iterations': Integer(10, 1000),\n",
    "#                  'depth': Integer(1, 8),\n",
    "#                  'learning_rate': Real(0.01, 1.0, 'log-uniform'),\n",
    "#                  'random_strength': Real(1e-9, 10, 'log-uniform'),\n",
    "#                  'bagging_temperature': Real(0.0, 1.0),\n",
    "#                  'border_count': Integer(1, 255),\n",
    "#                  'l2_leaf_reg': Integer(2, 30),\n",
    "#                  'scale_pos_weight':Real(0.01, 1.0, 'uniform')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Setting up BayesSearchCV\n",
    "# opt = BayesSearchCV(clf,\n",
    "#                     search_spaces,\n",
    "#                     scoring=roc_auc,\n",
    "#                     cv=skf,\n",
    "#                     n_iter=100,\n",
    "#                     n_jobs=1,  # use just 1 job with CatBoost in order to avoid segmentation fault\n",
    "#                     return_train_score=False,\n",
    "#                     refit=True,\n",
    "#                     optimizer_kwargs={'base_estimator': 'GP'},\n",
    "#                     random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Random Forest\n",
    "\n",
    "# rf = RandomForestClassifier(\n",
    "#     n_estimators=421, \n",
    "#     max_depth=15,\n",
    "#     max_features=3,\n",
    "#     min_samples_split=8, \n",
    "#     class_weight=\"balanced\",\n",
    "#     bootstrap=True,\n",
    "#     criterion='entropy',\n",
    "#     random_state=100\n",
    "#     )\n",
    "\n",
    "# rf.fit(X_train.drop(columns=['ID', 'ID2']), y_train)\n",
    "# preds_rf = rf.predict_proba(X_test.drop(columns=['ID','ID2'], axis=1))\n",
    "# y_test = pd.DataFrame(preds_rf)\n",
    "# y_test.columns = le.inverse_transform(y_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | colsam... | colsam... |   gamma   | learni... | max_de... | max_depth | min_ch... | n_esti... | reg_alpha | reg_la... | subsample |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.8733  \u001b[0m | \u001b[0m 0.4229  \u001b[0m | \u001b[0m 0.7231  \u001b[0m | \u001b[0m 5.719e-0\u001b[0m | \u001b[0m 0.3093  \u001b[0m | \u001b[0m 2.935   \u001b[0m | \u001b[0m 4.617   \u001b[0m | \u001b[0m 0.9313  \u001b[0m | \u001b[0m 274.6   \u001b[0m | \u001b[0m 0.3968  \u001b[0m | \u001b[0m 538.8   \u001b[0m | \u001b[0m 0.425   \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m 0.7167  \u001b[0m | \u001b[0m 0.6884  \u001b[0m | \u001b[0m 0.2124  \u001b[0m | \u001b[0m 0.4391  \u001b[0m | \u001b[0m 0.03711 \u001b[0m | \u001b[0m 13.41   \u001b[0m | \u001b[0m 20.87   \u001b[0m | \u001b[0m 2.793   \u001b[0m | \u001b[0m 141.3   \u001b[0m | \u001b[0m 0.1981  \u001b[0m | \u001b[0m 800.7   \u001b[0m | \u001b[0m 0.9686  \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.8658  \u001b[0m | \u001b[0m 0.3203  \u001b[0m | \u001b[0m 0.6954  \u001b[0m | \u001b[0m 0.4382  \u001b[0m | \u001b[0m 0.8957  \u001b[0m | \u001b[0m 1.701   \u001b[0m | \u001b[0m 1.953   \u001b[0m | \u001b[0m 0.8492  \u001b[0m | \u001b[0m 620.8   \u001b[0m | \u001b[0m 0.09835 \u001b[0m | \u001b[0m 421.1   \u001b[0m | \u001b[0m 0.9583  \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.872   \u001b[0m | \u001b[0m 0.1366  \u001b[0m | \u001b[0m 0.7471  \u001b[0m | \u001b[0m 0.4986  \u001b[0m | \u001b[0m 0.2337  \u001b[0m | \u001b[0m 9.539   \u001b[0m | \u001b[0m 7.97    \u001b[0m | \u001b[0m 3.134   \u001b[0m | \u001b[0m 621.1   \u001b[0m | \u001b[0m 0.3783  \u001b[0m | \u001b[0m 425.3   \u001b[0m | \u001b[0m 0.2561  \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.7077  \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 20.0    \u001b[0m | \u001b[0m 50.0    \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 479.6   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 539.9   \u001b[0m | \u001b[0m 0.01    \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.7077  \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 1e-09   \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 4.426   \u001b[0m | \u001b[0m 50.0    \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 700.0   \u001b[0m | \u001b[0m 1e-09   \u001b[0m | \u001b[0m 475.4   \u001b[0m | \u001b[0m 0.01    \u001b[0m |\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.model_selection import cross_val_score\n",
    "pbounds = {\n",
    "    'learning_rate': (0.01, 1.0),\n",
    "    'min_child_weight': (0, 10),\n",
    "    'max_depth': (0, 50),\n",
    "    'max_delta_step': (0, 20),\n",
    "    'subsample': (0.01, 1.0),\n",
    "    'colsample_bytree': (0.01, 1.0),\n",
    "    'colsample_bylevel': (0.01, 1.0),\n",
    "    'reg_lambda': (1e-9, 1000),\n",
    "    'reg_alpha': (1e-9, 1.0),\n",
    "    'gamma': (1e-9, 0.5),\n",
    "    'min_child_weight': (0, 5),\n",
    "    'n_estimators': (50, 700)\n",
    "}\n",
    "def xgboost_hyper_param(learning_rate,\n",
    "                        n_estimators,\n",
    "                        max_depth,\n",
    "                        subsample,\n",
    "                        gamma,\n",
    "                        min_child_weight,\n",
    "                        max_delta_step,\n",
    "                       colsample_bytree,\n",
    "                       colsample_bylevel,\n",
    "                       reg_lambda,\n",
    "                       reg_alpha):\n",
    "    max_depth = int(max_depth)\n",
    "    n_estimators = int(n_estimators)\n",
    "    clf = XGBClassifier(\n",
    "        max_depth=max_depth,\n",
    "        learning_rate=learning_rate,\n",
    "        n_estimators=n_estimators,\n",
    "        gamma=gamma,\n",
    "        min_child_weight=min_child_weight,\n",
    "        colsample_bytree=colsample_bytree,\n",
    "        colsample_bylevel=colsample_bylevel,\n",
    "        reg_lambda=reg_lambda,\n",
    "        reg_alpha=reg_alpha,\n",
    "        max_delta_step=max_delta_step\n",
    "        )\n",
    "    return np.mean(cross_val_score(clf, X_train.drop(columns=['ID', 'ID2'], axis=1), y_train, cv=3))\n",
    "optimizer = BayesianOptimization(\n",
    "    f=xgboost_hyper_param,\n",
    "    pbounds=pbounds,\n",
    "    random_state=1,\n",
    ")\n",
    "\n",
    "optimizer.maximize(init_points=3,n_iter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-7b8ae8f659a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mreg_alpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3968\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         max_delta_step=3)\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mxgb_cl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ID'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ID2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mpreds_xgb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb_cl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ID'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'ID2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds_xgb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/jupyter/lib/python3.6/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, callbacks)\u001b[0m\n\u001b[1;32m    822\u001b[0m                               \u001b[0mevals_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxgb_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxgb_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 824\u001b[0;31m                               callbacks=callbacks)\n\u001b[0m\u001b[1;32m    825\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    826\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb_options\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"objective\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/jupyter/lib/python3.6/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m    210\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/jupyter/lib/python3.6/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/jupyter/lib/python3.6/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1367\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n\u001b[1;32m   1368\u001b[0m                                                     \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1369\u001b[0;31m                                                     dtrain.handle))\n\u001b[0m\u001b[1;32m   1370\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1371\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_margin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## XGboost\n",
    "\n",
    "xgb_cl = XGBClassifier(\n",
    "        max_depth=13,\n",
    "        learning_rate=0.3093,\n",
    "        n_estimators=275,\n",
    "        gamma=0.5719,\n",
    "        min_child_weight=0.9313,\n",
    "        colsample_bytree=0.422,\n",
    "        colsample_bylevel=0.723,\n",
    "        reg_alpha=0.3968,\n",
    "        max_delta_step=3)\n",
    "xgb_cl.fit(X_train.drop(columns=['ID', 'ID2']),y_train)\n",
    "preds_xgb = xgb_cl.predict_proba(X_test.drop(columns=['ID','ID2'], axis=1))\n",
    "y_test = pd.DataFrame(preds_xgb)\n",
    "y_test.columns = le.inverse_transform(y_test.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W7NYpdx0nc4s"
   },
   "source": [
    "### Submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "H8VHTNphyCDC",
    "outputId": "462812c6-d47a-4720-eaef-7d74240e2484"
   },
   "outputs": [],
   "source": [
    "answer_mass = []\n",
    "for i in range(X_test.shape[0]):\n",
    "    id = X_test['ID'].iloc[i]\n",
    "    for c in y_test.columns:\n",
    "        answer_mass.append([id + ' X ' + c, y_test[c].iloc[i]])\n",
    "\n",
    "df_answer = pd.DataFrame(answer_mass)\n",
    "df_answer.columns = ['ID X PCODE', 'Label']\n",
    "for i in range(df_answer.shape[0]):\n",
    "    if df_answer['ID X PCODE'].iloc[i] in true_values:\n",
    "        df_answer['Label'].iloc[i] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zgIYeYwzzP1B"
   },
   "outputs": [],
   "source": [
    "df_answer.reset_index(drop=True, inplace=True)\n",
    "df_answer.to_csv('submission24.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1ZTTmnHMmev1"
   },
   "source": [
    "Submit"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Baseline1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
